{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71a3a51a",
   "metadata": {},
   "source": [
    "# Benchmarking\n",
    "In this notebook we will run operations and compare their runtime to benchmark performance of the given GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33e723b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<NVIDIA GeForce RTX 2080 SUPER on Platform: NVIDIA CUDA (1 refs)>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyclesperanto_prototype as cle\n",
    "import numpy as np\n",
    "import timeit\n",
    "from functools import partial\n",
    "from skimage.io import imread, imshow\n",
    "import matplotlib.pyplot as plt\n",
    "cle.select_device('TX')  # TODO: change to your GPU\n",
    "cle.set_wait_for_kernel_finish(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c00e005",
   "metadata": {},
   "outputs": [],
   "source": [
    "warm_up_iter = 1\n",
    "eval_iter = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e01eb2f",
   "metadata": {},
   "source": [
    "### Gaussian blur"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314562c2",
   "metadata": {},
   "source": [
    "Let's setup import the necessary functions and setup common input parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2cef34ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.filters import gaussian\n",
    "\n",
    "# gaussian sigma to run on\n",
    "sigma = 5\n",
    "# create a test image\n",
    "array = np.random.random([100, 1000, 1000]).astype(np.float32)\n",
    "gpu_array = cle.push(array)\n",
    "# compute the size of the image in MB\n",
    "array_mb = array.size * array.itemsize / 1000000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8a8bea",
   "metadata": {},
   "source": [
    "We then prepare a minimal function containing the code we want to benchmark. In this case, we want to measure the time it takes to execute a Gaussian blur on an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7ad4b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cle_gaussian(arr, sigma):\n",
    "    cle.gaussian_blur(arr, sigma_x=sigma, sigma_y=sigma, sigma_z=sigma)\n",
    "\n",
    "def ski_gaussian(arr, sigma):\n",
    "    gaussian(arr, sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4e6041",
   "metadata": {},
   "source": [
    "We can then run the benchmarking script on the function to evaluate. Here we are using the built-in package `timeit` from python.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d911e7f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing (100, 1000, 1000) of 400.0 Mb ... 0.25477212097030133 s\n"
     ]
    }
   ],
   "source": [
    "# GPU evaluation\n",
    "partial_function = partial(cle_gaussian, gpu_array, sigma)\n",
    "_ = timeit.timeit(partial_function, number=warm_up_iter)\n",
    "gpu_in_s = timeit.timeit(partial_function, number=eval_iter)\n",
    "print(f\"Processing {array.shape} of {array_mb} Mb ... {gpu_in_s} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aadcbb6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing (100, 1000, 1000) of 400.0 Mb ... 14.080915375961922 s\n"
     ]
    }
   ],
   "source": [
    "# CPU evaluation\n",
    "partial_function = partial(ski_gaussian, array, sigma)\n",
    "_ = timeit.timeit(partial_function, number=warm_up_iter)\n",
    "cpu_in_s = timeit.timeit(partial_function, number=eval_iter)\n",
    "print(f\"Processing {array.shape} of {array_mb} Mb ... {cpu_in_s} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70b46fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are x55.2686664550841 times faster on GPU than on CPU.\n"
     ]
    }
   ],
   "source": [
    "print(f\"We are x{cpu_in_s / gpu_in_s} times faster on GPU than on CPU.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae8122a",
   "metadata": {},
   "source": [
    "### Otsu Threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd89bcdd",
   "metadata": {},
   "source": [
    "We can, this way, look at the execution time of other operations. The Otsu thresholding is an other interesting case as a part of the algorithm cannot be distributed on the GPU. This means that, even if we can have a speed up, it will not be as good as the other operations more adapted to parallelization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3464b978",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.filters import threshold_otsu\n",
    "\n",
    "# create a test image\n",
    "array = np.random.random([100, 1000, 1000]).astype(np.float32)\n",
    "gpu_array = cle.push(array)\n",
    "# compute the size of the image in MB\n",
    "array_mb = array.size * array.itemsize / 1000000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035b1370",
   "metadata": {},
   "source": [
    "We define the function to evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6198441",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cle_otsu(arr):\n",
    "    cle.threshold_otsu(arr)\n",
    "\n",
    "def ski_otsu(arr):\n",
    "    arr > threshold_otsu(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7df143",
   "metadata": {},
   "source": [
    "We run both timers for GPU and CPU, and compare the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cede194f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing (100, 1000, 1000) of 400.0 Mb ... 0.1980779010336846 s\n"
     ]
    }
   ],
   "source": [
    "# GPU evaluation\n",
    "partial_function = partial(cle_otsu, gpu_array)\n",
    "_ = timeit.timeit(partial_function, number=warm_up_iter)\n",
    "gpu_in_s = timeit.timeit(partial_function, number=eval_iter)\n",
    "print(f\"Processing {array.shape} of {array_mb} Mb ... {gpu_in_s} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba82cd2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing (100, 1000, 1000) of 400.0 Mb ... 2.864950605086051 s\n"
     ]
    }
   ],
   "source": [
    "# CPU evaluation\n",
    "partial_function = partial(ski_otsu, array)\n",
    "_ = timeit.timeit(partial_function, number=warm_up_iter)\n",
    "cpu_in_s = timeit.timeit(partial_function, number=eval_iter)\n",
    "print(f\"Processing {array.shape} of {array_mb} Mb ... {cpu_in_s} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98be6c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are x14.46375688623056 times faster on GPU than on CPU.\n"
     ]
    }
   ],
   "source": [
    "print(f\"We are x{cpu_in_s / gpu_in_s} times faster on GPU than on CPU.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1d5ee5",
   "metadata": {},
   "source": [
    "### Mini-Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d747e3",
   "metadata": {},
   "source": [
    "Now, single operation benchmarking is easy, they however do not show real case application. Let's say, first try to mimic a pipeline processing with a basic set of operations: gaussian, threshold, and labeling.\n",
    "\n",
    "Here, we do not want a random value image, so we made this little function to generate a simple image with a random blobs distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56ec5a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a blobs like image\n",
    "def create_test_image(shape, nb_points):\n",
    "    sigma = 10\n",
    "    pointlist = np.random.random([3, nb_points]) * shape[-1]\n",
    "    image = cle.create(shape)\n",
    "    cle.pointlist_to_labelled_spots(pointlist, image)\n",
    "    blobs = cle.maximum_sphere(image, radius_x=10, radius_y=10, radius_z=10)\n",
    "    binary_blobs = cle.greater_constant(blobs, constant=0)\n",
    "    return cle.pull(binary_blobs).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd7fa9e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000000 4 400.0\n"
     ]
    }
   ],
   "source": [
    "from skimage.measure import label\n",
    "\n",
    "# create a test image\n",
    "array = create_test_image((100,1000,1000), 500)\n",
    "gpu_array = cle.push(array)\n",
    "# compute the size of the image in MB\n",
    "array_mb = array.size * array.itemsize / 1000000\n",
    "print(array.size, array.itemsize, array_mb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c383b6",
   "metadata": {},
   "source": [
    "We can then define our mini-pipeline to evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "997fc452",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cle_pipeline(arr):\n",
    "    blurred = cle.gaussian_blur(arr, sigma_x=3, sigma_y=3, sigma_z=3)\n",
    "    binary = cle.threshold_otsu(blurred)\n",
    "    labels = cle.connected_components_labeling_box(binary)\n",
    "\n",
    "def ski_pipeline(arr):\n",
    "    blurred = gaussian(arr, sigma=3)\n",
    "    binary = blurred>threshold_otsu(blurred)\n",
    "    labels = label(binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f0647d",
   "metadata": {},
   "source": [
    "And run the benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2d48d5a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing (100, 1000, 1000) of 400.0 Mb ... 0.6984281110344455 s\n"
     ]
    }
   ],
   "source": [
    "# GPU evaluation\n",
    "partial_function = partial(cle_pipeline, gpu_array)\n",
    "_ = timeit.timeit(partial_function, number=warm_up_iter)\n",
    "gpu_in_s = timeit.timeit(partial_function, number=eval_iter)\n",
    "print(f\"Processing {array.shape} of {array_mb} Mb ... {gpu_in_s} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f430c853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing (100, 1000, 1000) of 400.0 Mb ... 14.165793296997435 s\n"
     ]
    }
   ],
   "source": [
    "# CPU evaluation\n",
    "partial_function = partial(ski_pipeline, array)\n",
    "_ = timeit.timeit(partial_function, number=warm_up_iter)\n",
    "cpu_in_s = timeit.timeit(partial_function, number=eval_iter)\n",
    "print(f\"Processing {array.shape} of {array_mb} Mb ... {cpu_in_s} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac34de7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are x20.282392809213256 times faster on GPU than on CPU.\n"
     ]
    }
   ],
   "source": [
    "print(f\"We are x{cpu_in_s / gpu_in_s} times faster on GPU than on CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2333e0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
