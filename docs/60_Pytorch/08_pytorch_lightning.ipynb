{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e0b62c3",
   "metadata": {},
   "source": [
    "# Pytorch lightning\n",
    "\n",
    "As you might have noticed, torch leaves many responsibilities to the user regarding choices of device, writing of the training loop, loss logging and model checkpointing. This is good and bad at the same time since it provides a lot of flexibility, but re-writing lots of boilerplate code which will be very similar across projects.\n",
    "\n",
    "[Pytorch_lightning](https://lightning.ai/docs/pytorch/stable/) aims to make many things easier by abstracting them from the user. It automatically handles devices, logs to tensorboard, offers plugins for model checkpointing, makes restoration of models from checkpointing easier and is able to manage distributed training across multiple GPUs or multiple nodes. In this notebook, we will modify the existing code using this library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4817cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "\n",
    "from pathlib import Path\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1febf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can have lightning take care of fixing random seeds for numpy, torch and cuda to ensure reproducibility of the trained models\n",
    "pl.seed_everything(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59c6408",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_present = torch.cuda.is_available()\n",
    "ndevices = torch.cuda.device_count()\n",
    "use_cuda = cuda_present and ndevices > 0\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")  # \"cuda:0\" ... default device, \"cuda:1\" would be GPU index 1, \"cuda:2\" etc\n",
    "print(\"number of devices:\", ndevices, \"\\tchosen device:\", device, \"\\tuse_cuda=\", use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b00627",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from data import DSBData, get_dsb2018_train_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0df807c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.networks.nets import BasicUNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d14c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_files, train_lbl_files = get_dsb2018_train_files()\n",
    "\n",
    "train_data = DSBData(\n",
    "    image_files=train_img_files,\n",
    "    label_files=train_lbl_files,\n",
    "    target_shape=(256, 256)\n",
    ")\n",
    "\n",
    "print(len(train_data))\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True, num_workers=1, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05026e0",
   "metadata": {},
   "source": [
    "Using lightning requires us to build a new neural network model by inheriting from the base class. This basically means to re-order parts of the existing code base into various member functions that have to be overridden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91cdc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegmentationNetwork(pl.LightningModule):\n",
    "    def __init__(self, \n",
    "                 features=[16, 16, 32, 64, 128, 16],\n",
    "                 activation=\"relu\",\n",
    "                 normalization=\"batch\",\n",
    "                 dropout=0.25\n",
    "                ):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "        self.model = BasicUNet(\n",
    "            spatial_dims=2,\n",
    "            in_channels=1,\n",
    "            out_channels=1,\n",
    "            features=features,\n",
    "            act=activation,\n",
    "            norm=normalization,\n",
    "            dropout=dropout,\n",
    "        )\n",
    "        self.output_activation = torch.nn.Sigmoid()\n",
    "        self.loss_function = torch.nn.BCEWithLogitsLoss(reduction=\"mean\")\n",
    "    \n",
    "    def forward(self, x):\n",
    "        logits = self.model(x)\n",
    "        prediction = self.output_activation(logits)  # apply the sigmoid to get a value in [0, 1] for each pixel\n",
    "\n",
    "        return {\n",
    "            'logits': logits,\n",
    "            'prediction': prediction\n",
    "        }\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # NOTE: no manual device mapping is required, lightning does that for you!\n",
    "        X, y = batch\n",
    "        pred_dict = self(X)\n",
    "\n",
    "        batch_loss = self.loss_function(pred_dict[\"logits\"], y)\n",
    "        self.log(\"train_loss\", batch_loss, prog_bar=True)\n",
    "\n",
    "        return batch_loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=1.e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5f5249",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SegmentationNetwork()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76249c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_params = list(model.parameters())[0].clone().detach()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3101d471",
   "metadata": {},
   "source": [
    "Now we set up a checkpoint callback that takes care of storing model weights and define a trainer instance which will manage running the training loop and device handling for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08e53fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "logfolder = Path(\"lightning_outputs\")\n",
    "if not logfolder.is_dir():\n",
    "    logfolder.mkdir()\n",
    "\n",
    "ckpt_callback = ModelCheckpoint(\n",
    "    filename='{epoch:03.0f}-{train_loss:.3f}',\n",
    "    save_last=True,\n",
    "    save_top_k=1,\n",
    "    monitor=\"train_loss\",\n",
    "    every_n_epochs=1\n",
    ")\n",
    "\n",
    "max_nepochs = 3\n",
    "log_interval = 1\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    default_root_dir=logfolder,\n",
    "    max_epochs=max_nepochs,\n",
    "    log_every_n_steps=log_interval,\n",
    "    accelerator=\"gpu\" if use_cuda else \"cpu\",\n",
    "    devices=ndevices if use_cuda else 1,\n",
    "    callbacks=[\n",
    "        ckpt_callback\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7e46ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --port 6006 --logdir ./lightning_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af63aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model, train_dataloaders=train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f458ac0",
   "metadata": {},
   "source": [
    "Restoration of model states from checkpoints is a bit easier than before as well, because it does not require you to re-create a model instance with the same hyperparameters as the checkpointed model (which might be unknown when only the checkpoint is available)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5eb37fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_params = list(model.parameters())[0].clone().detach()\n",
    "assert not torch.allclose(init_params, final_params)\n",
    "\n",
    "# when to reload chkp, e.g. for doing inference\n",
    "model_from_ckpt = SegmentationNetwork.load_from_checkpoint(\n",
    "    ckpt_callback.last_model_path\n",
    ")\n",
    "loaded_params = list(model_from_ckpt.parameters())[0].cpu()\n",
    "assert torch.allclose(loaded_params, final_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5434b1c",
   "metadata": {},
   "source": [
    "## Look at some predictions\n",
    "\n",
    "Now that the model has been trained for a little bit, we are looking at the predictions again. Usually model training has to be peformed longer, so don't expect any wonders. Also keep in mind that the predictions here are based on the data the model was trained on. Those predictions might be far better than those on data not used during training. But this is a story for later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e4a7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77969a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we get a batch of data\n",
    "for batch in train_loader:\n",
    "    X, y = batch\n",
    "    break\n",
    "\n",
    "# convert to 0/1 range on each pixel\n",
    "prediction_dict = model_from_ckpt(X.to(model_from_ckpt.device))\n",
    "prediction = prediction_dict[\"prediction\"]\n",
    "prediction_binary = (prediction > 0.5).to(torch.uint8)\n",
    "\n",
    "sidx = 0\n",
    "plt.subplot(131)\n",
    "plt.imshow(X[sidx, 0].numpy(), cmap=\"gray\")\n",
    "plt.title(\"Input\")\n",
    "\n",
    "plt.subplot(132)\n",
    "plt.imshow(y[sidx, 0].numpy(), cmap=\"gray\")\n",
    "plt.title(\"Ground truth\")\n",
    "\n",
    "plt.subplot(133)\n",
    "plt.imshow(prediction_binary.detach()[sidx, 0].cpu().numpy(), cmap=\"gray\")\n",
    "plt.title(\"Predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbaf4e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1a3b5d-c55a-48ad-aafc-eaba0d5eeabf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56401a4f-b373-493a-a58d-7ecf2e199acd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_intro_env",
   "language": "python",
   "name": "torch_intro_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
