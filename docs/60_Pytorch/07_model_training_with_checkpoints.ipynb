{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdad11e3",
   "metadata": {},
   "source": [
    "# Training with checkpoints\n",
    "\n",
    "The currently developed pipeline has the major drawbacks that the states of the parameters are not saved. So after training, when closing the notebook, you no longer have access to the trained model. This has to be fixed to save you hours of re-training models over and over again. Also, it might be a good idea to save some \"snapshots\" of model parameters obtained during training, not only once training is finished. This can be achieved using checkpointing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b53d6258",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c7b1d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed0c5a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of devices: 0 \tchosen device: cpu \tuse_cuda= False\n"
     ]
    }
   ],
   "source": [
    "cuda_present = torch.cuda.is_available()\n",
    "ndevices = torch.cuda.device_count()\n",
    "use_cuda = cuda_present and ndevices > 0\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")  # \"cuda:0\" ... default device, \"cuda:1\" would be GPU index 1, \"cuda:2\" etc\n",
    "print(\"number of devices:\", ndevices, \"\\tchosen device:\", device, \"\\tuse_cuda=\", use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b71c1cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from data import DSBData, get_dsb2018_train_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a00f4e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.networks.nets import BasicUNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "451c0804",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████| 382/382 [00:14<00:00, 27.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_img_files, train_lbl_files = get_dsb2018_train_files()\n",
    "\n",
    "train_data = DSBData(\n",
    "    image_files=train_img_files,\n",
    "    label_files=train_lbl_files,\n",
    "    target_shape=(256, 256)\n",
    ")\n",
    "\n",
    "print(len(train_data))\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True, num_workers=1, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a396a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BasicUNet features: (16, 16, 32, 64, 128, 16).\n"
     ]
    }
   ],
   "source": [
    "model = BasicUNet(\n",
    "    spatial_dims=2,\n",
    "    in_channels=1,\n",
    "    out_channels=1,\n",
    "    features=[16, 16, 32, 64, 128, 16],\n",
    "    act=\"relu\",\n",
    "    norm=\"batch\",\n",
    "    dropout=0.25,\n",
    ")\n",
    "\n",
    "# transfer the model to the chosen device\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0402b8c",
   "metadata": {},
   "source": [
    "Training of a neural network means updating its parameters (weights) using a strategy that involves the gradients of a loss function with respect to the model parameters in order to adjust model weights to minimize this loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7aa63020",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1.e-3)\n",
    "init_params = list(model.parameters())[0].clone().detach()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370497e6",
   "metadata": {},
   "source": [
    "Such a training is performed by iterating over the batches of the training dataset multiple times. Each full iteration over the dataset is termed an epoch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de7f9cd",
   "metadata": {},
   "source": [
    "During or after training the tensorboard logs can be visualized as follows: in a terminal, type\n",
    "\n",
    "```shell\n",
    "tensorboard --logdir \"path/to/logs\",\n",
    "```\n",
    "\n",
    "then open a browser on `localhost:6006` (or whichever port the tensorboard server outputted as running on).\n",
    "Alternatively, tensorboard can be accessed from jupyter as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b9a00e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-b5fba1efcf9c9acc\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-b5fba1efcf9c9acc\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --port 6006 --logdir ./logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f10b4327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 Batch: 0 Total samples processed: 32 Loss: 0.6792986392974854\n",
      "Train Epoch: 1 Batch: 1 Total samples processed: 64 Loss: 0.639143705368042\n",
      "Train Epoch: 1 Batch: 2 Total samples processed: 96 Loss: 0.6133203506469727\n",
      "Train Epoch: 1 Batch: 3 Total samples processed: 128 Loss: 0.5941408276557922\n",
      "Train Epoch: 1 Batch: 4 Total samples processed: 160 Loss: 0.5772541165351868\n",
      "Train Epoch: 1 Batch: 5 Total samples processed: 192 Loss: 0.5588562488555908\n",
      "Train Epoch: 1 Batch: 6 Total samples processed: 224 Loss: 0.5604053139686584\n",
      "Train Epoch: 1 Batch: 7 Total samples processed: 256 Loss: 0.5290923714637756\n",
      "Train Epoch: 2 Batch: 0 Total samples processed: 32 Loss: 0.5261285305023193\n",
      "Train Epoch: 2 Batch: 1 Total samples processed: 64 Loss: 0.5121616125106812\n",
      "Train Epoch: 2 Batch: 2 Total samples processed: 96 Loss: 0.4993342161178589\n",
      "Train Epoch: 2 Batch: 3 Total samples processed: 128 Loss: 0.4973333477973938\n",
      "Train Epoch: 2 Batch: 4 Total samples processed: 160 Loss: 0.47704416513442993\n",
      "Train Epoch: 2 Batch: 5 Total samples processed: 192 Loss: 0.4746968746185303\n",
      "Train Epoch: 2 Batch: 6 Total samples processed: 224 Loss: 0.463951975107193\n",
      "Train Epoch: 2 Batch: 7 Total samples processed: 256 Loss: 0.4443892538547516\n"
     ]
    }
   ],
   "source": [
    "max_nepochs = 2\n",
    "log_interval = 1\n",
    "writer = SummaryWriter(log_dir=\"logs\", comment=\"this is the test of SummaryWriter\")\n",
    "\n",
    "model.train(True)\n",
    "\n",
    "chpfolder = Path(\"chkpts\")\n",
    "if not chpfolder.is_dir():\n",
    "    chpfolder.mkdir()\n",
    "\n",
    "# expects raw unnormalized scores and combines sigmoid + BCELoss for better\n",
    "# numerical stability.\n",
    "# expects B x C x W x D\n",
    "loss_function = torch.nn.BCEWithLogitsLoss(reduction=\"mean\")\n",
    "\n",
    "for epoch in range(1, max_nepochs + 1):\n",
    "    for batch_idx, (X, y) in enumerate(train_loader):\n",
    "        # the inputs and labels have to be on the same device as the model\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        prediction_logits = model(X)\n",
    "        \n",
    "        batch_loss = loss_function(prediction_logits, y)\n",
    "\n",
    "        batch_loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print(\n",
    "                \"Train Epoch:\",\n",
    "                epoch,\n",
    "                \"Batch:\",\n",
    "                batch_idx,\n",
    "                \"Total samples processed:\",\n",
    "                (batch_idx + 1) * train_loader.batch_size,\n",
    "                \"Loss:\",\n",
    "                batch_loss.item(),\n",
    "            )\n",
    "            writer.add_scalar(\"Loss/train\", batch_loss.item(), batch_idx)\n",
    "    # epoch finished, we save the model\n",
    "    cpath = chpfolder / f\"epoch-{epoch:03.0f}.pth\"\n",
    "    torch.save(\n",
    "        {\n",
    "            \"final_epoch\": epoch,\n",
    "            \"model_state_dict\": model.state_dict(),\n",
    "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "        },\n",
    "        cpath,\n",
    "    )\n",
    "\n",
    "    assert cpath.is_file() and cpath.stat().st_size > 0\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81348f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_params = list(model.parameters())[0].clone().detach()\n",
    "assert not torch.allclose(init_params, final_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebe2882",
   "metadata": {},
   "source": [
    "Restoring the model from a saved checkpoint, e.g. for doing inference, can be done as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc2e1428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BasicUNet features: (16, 16, 32, 64, 128, 16).\n"
     ]
    }
   ],
   "source": [
    "payload = torch.load(cpath)\n",
    "model_from_ckpt = BasicUNet(\n",
    "    spatial_dims=2,\n",
    "    in_channels=1,\n",
    "    out_channels=1,\n",
    "    features=[16, 16, 32, 64, 128, 16],\n",
    "    act=\"relu\",\n",
    "    norm=\"batch\",\n",
    "    dropout=0.25,\n",
    ")\n",
    "model_from_ckpt.load_state_dict(payload['model_state_dict'])\n",
    "# continue learning/training after this\n",
    "loaded_params = list(model_from_ckpt.parameters())[0]\n",
    "assert torch.allclose(loaded_params, final_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_intro_env",
   "language": "python",
   "name": "torch_intro_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
